注意力转移机制

注意力机制对不同信息的关注程度（重要程度）由**权值**来体现，注意力机制可以视为**查询矩阵**(Query)、**键**(key)以及**加权平均值**构成了多层感知机(Multilayer Perceptron, MLP)。

注意力的思想，类似于寻址。给定Target中的某个元素Query，通过计算Query和各个Key的**相似性**或**相关性**，得到每个Key对应Value的**权重系数**，然后对Value进行加权求和，即得到最终的Attention数值。所以，本质上Attention机制是Source中元素的Value值进行加权求和，而Query和Key用来计算对应Value的权重系数。