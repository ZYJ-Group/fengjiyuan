import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import time
from utils import styler, compute_rd_image, plot_isar_comparison, get_isar_data

# ==========================================
# 0. ä¸“ç”¨æ±‚è§£å™¨å®šä¹‰ (Huber Solver)
# ==========================================
class HuberISARSolver:
    """
    åŒ…å« Huber Smoothing ç®—æ³•çš„ ISAR æ±‚è§£å™¨
    """
    def __init__(self, raw_sparse, mask, max_iter=100, tol=1e-5):
        self.y = raw_sparse
        self.mask = mask
        self.Mask2D = mask[None, :]
        self.max_iter = max_iter
        self.tol = tol
        self.loss_history = []
        
    def _A_op(self, image_x):
        """æ­£å‘ç®—å­: Image -> Data (Undersampled)"""
        # Image (RD Domain) -> Data (Time/Freq Domain)
        return np.fft.ifft2(np.fft.ifftshift(image_x), norm='ortho') * self.Mask2D

    def _AT_op(self, data_y):
        """ä¼´éšç®—å­: Data -> Image"""
        # Data -> Image
        return np.fft.fftshift(np.fft.fft2(data_y * self.Mask2D, norm='ortho'))

    def _grad_huber(self, x, mu):
        """è®¡ç®— Huber å¹³æ»‘é¡¹çš„æ¢¯åº¦"""
        abs_x = np.abs(x)
        grad = np.zeros_like(x)
        
        # Case 1: |x| <= mu (äºŒæ¬¡å‡½æ•°åŒºåŸŸ)
        mask_small = abs_x <= mu
        grad[mask_small] = x[mask_small] / mu
        
        # Case 2: |x| > mu (çº¿æ€§åŒºåŸŸï¼Œç±»ä¼¼ L1)
        mask_large = ~mask_small
        grad[mask_large] = x[mask_large] / (abs_x[mask_large] + 1e-15)
        
        return grad

    def huber_gradient_descent(self, lambda_ratio=0.05, alpha=1.0, mu=1e-2):
        """åŸºç¡€ Huber æ¢¯åº¦ä¸‹é™"""
        x = self._AT_op(self.y)
        lambda_val = lambda_ratio * np.max(np.abs(x))
        self.loss_history = []
        
        for i in range(self.max_iter):
            x_prev = x.copy()
            
            # 1. æ•°æ®æ‹Ÿåˆé¡¹æ¢¯åº¦
            Ax = self._A_op(x)
            res = Ax - self.y
            grad_data = self._AT_op(res)
            
            # 2. æ­£åˆ™é¡¹æ¢¯åº¦ (Huber)
            grad_reg = lambda_val * self._grad_huber(x, mu)
            
            # 3. æ¢¯åº¦ä¸‹é™æ›´æ–°
            x = x - alpha * (grad_data + grad_reg)
            
            # è®°å½•
            loss = 0.5 * np.linalg.norm(res)**2 + lambda_val * np.sum(np.abs(x))
            self.loss_history.append(loss)
            
            if np.linalg.norm(x - x_prev) / (np.linalg.norm(x_prev) + 1e-12) < self.tol:
                break
        return x

    def huber_nesterov(self, lambda_ratio=0.05, alpha=1.0, mu=1e-2):
        """åŠ é€Ÿ Huber æ¢¯åº¦ä¸‹é™ (Nesterov)"""
        x = self._AT_op(self.y)
        y_k = x.copy()
        t_k = 1.0
        lambda_val = lambda_ratio * np.max(np.abs(x))
        self.loss_history = []
        
        for i in range(self.max_iter):
            x_prev = x.copy()
            
            # åœ¨ y_k (å¤–æ¨ç‚¹) å¤„è®¡ç®—æ¢¯åº¦
            Ay = self._A_op(y_k)
            res = Ay - self.y
            grad_data = self._AT_op(res)
            grad_reg = lambda_val * self._grad_huber(y_k, mu)
            
            # æ¢¯åº¦æ›´æ–°
            x = y_k - alpha * (grad_data + grad_reg)
            
            # Nesterov åŠ¨é‡æ›´æ–°
            t_next = (1 + np.sqrt(1 + 4 * t_k**2)) / 2
            beta = (t_k - 1) / t_next
            y_k = x + beta * (x - x_prev)
            t_k = t_next
            
            loss = 0.5 * np.linalg.norm(res)**2 + lambda_val * np.sum(np.abs(x))
            self.loss_history.append(loss)
            
            if np.linalg.norm(x - x_prev) / (np.linalg.norm(x_prev) + 1e-12) < self.tol:
                break
        return x

# ==========================================
# 1. ä¸»æ¸²æŸ“å‡½æ•°
# ==========================================
def render():
    # --- å…¨å±€é…ç½® ---
    st.markdown("""
    <style>
    .main-text {font-size:16px; line-height:1.6;}
    .math-box {background-color:#eef9fe; padding:15px; border-radius:10px; border-left: 5px solid #2196f3;}
    </style>
    """, unsafe_allow_html=True)
    
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS', 'sans-serif']
    plt.rcParams['axes.unicode_minus'] = False 
    
    tab_theory, tab_sim, tab_analysis = st.tabs(["ğŸ“– å¹³æ»‘åŒ–åŸç†", "ğŸ”¬ ISAR ä»¿çœŸå®éªŒå®¤", "ğŸ“‰ æ”¶æ•›æ€§èƒ½è¯Šæ–­"])

    # ==========================================
    # Tab 1: ç†è®ºæ·±åº¦è§£æ
    # ==========================================
    with tab_theory:
        st.markdown("### 1. ä¸ºä»€ä¹ˆéœ€è¦å¹³æ»‘ï¼Ÿ(Smoothing)")
        st.markdown("""
        <div class="main-text">
        åœ¨ LASSO é—®é¢˜ä¸­ï¼Œåœ¨é›¶ç‚¹å¤„æ˜¯<b>ä¸å¯å¯¼</b>çš„ã€‚
        è¿™å¯¼è‡´æˆ‘ä»¬æ— æ³•ç›´æ¥ä½¿ç”¨æ ‡å‡†çš„æ¢¯åº¦ä¸‹é™æ³•ï¼ˆGradient Descentï¼‰ï¼Œè€Œå¿…é¡»ä½¿ç”¨æ¬¡æ¢¯åº¦æ³•æˆ–è¿‘ç«¯æ¢¯åº¦æ³•ï¼ˆå¦‚ ISTAï¼‰ã€‚
        <br><br>
        <b>Huber å¹³æ»‘</b>æä¾›äº†ä¸€ç§æ›¿ä»£æ€è·¯ï¼šç”¨ä¸€ä¸ªå…‰æ»‘çš„å‡½æ•° $H_\mu(x)$ æ¥é€¼è¿‘ $|x|$ã€‚
        è¿™æ ·ï¼Œç›®æ ‡å‡½æ•°å°±å˜å¾—å¤„å¤„å¯å¯¼ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨é«˜æ•ˆçš„æ¢¯åº¦ç±»ç®—æ³•ï¼ˆç”šè‡³ L-BFGS ç­‰é«˜çº§ä¼˜åŒ–å™¨ï¼‰ã€‚
        </div>
        """, unsafe_allow_html=True)

        st.latex(r"""
        H_\mu(x) = \begin{cases} 
        \frac{1}{2\mu} x^2 & \text{if } |x| \le \mu \quad (\text{äºŒæ¬¡å‡½æ•°ï¼Œå¹³æ»‘}) \\
        |x| - \frac{\mu}{2} & \text{if } |x| > \mu \quad (\text{çº¿æ€§å‡½æ•°ï¼Œç¨€ç–})
        \end{cases}
        """)

        st.info("""
        **å‚æ•° $\mu$ (Mu) çš„ä½œç”¨**ï¼š
        *   **$\mu$ å¾ˆå¤§**ï¼šå‡½æ•°æ¥è¿‘ $x^2$ (Ridge å›å½’)ï¼Œå®¹æ˜“ä¼˜åŒ–ï¼Œä½†ç¨€ç–æ€§å·®ã€‚
        *   **$\mu$ å¾ˆå°**ï¼šå‡½æ•°æ¥è¿‘ $|x|$ (Lasso)ï¼Œç¨€ç–æ€§å¥½ï¼Œä½†æ¢¯åº¦å˜åŒ–å‰§çƒˆï¼Œä¼˜åŒ–å›°éš¾ã€‚
        """)

        # --- äº¤äº’æ¼”ç¤º: Huber å‡½æ•° ---
        st.markdown("#### ğŸ§ª å®éªŒï¼šHuber å‡½æ•°å½¢æ€")
        
        col_demo_ctrl, col_demo_viz = st.columns([1, 2])
        with col_demo_ctrl:
            mu_demo = st.slider("å¹³æ»‘å‚æ•° (Mu)", 0.01, 2.0, 0.5, 0.01)
            st.caption("è§‚å¯ŸåŸç‚¹é™„è¿‘çš„åœ†æ»‘ç¨‹åº¦ã€‚")
        
        with col_demo_viz:
            x = np.linspace(-3, 3, 500)
            l1 = np.abs(x)
            huber = np.where(np.abs(x) <= mu_demo, 0.5 * x**2 / mu_demo, np.abs(x) - 0.5 * mu_demo)
            
            fig, ax = plt.subplots(figsize=(8, 3))
            ax.plot(x, l1, 'k--', alpha=0.3, label='L1 Norm |x|')
            ax.plot(x, huber, 'b-', linewidth=2, label=f'Huber (mu={mu_demo})')
            
            # æ”¾å¤§åŸç‚¹ç»†èŠ‚
            ax.set_xlim(-1.5, 1.5)
            ax.set_ylim(0, 1.5)
            ax.set_title("L1 vs Huber Approximation")
            ax.legend()
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)

    # ==========================================
    # Tab 2: ä»¿çœŸè¿è¡Œ
    # ==========================================
    with tab_sim:
        st.markdown("### ğŸš€ Huber æ¢¯åº¦æ³•å®æˆ˜")
        
        col_param, col_main = st.columns([1, 3])
        
        with col_param:
            st.subheader("âš™ï¸ å‚æ•°è®¾ç½®")
            
            with st.expander("ğŸ“¡ é‡‡æ ·è®¾ç½®", expanded=True):
                sampling_rate = st.slider("é™é‡‡æ ·ç‡ (SR)", 0.1, 0.8, 0.4, 0.05)
            
            with st.expander("ğŸ§  ç®—æ³•è®¾ç½®", expanded=True):
                algo_type = st.radio("ä¼˜åŒ–ç­–ç•¥", ["Huber Gradient Descent", "Huber Accelerated (Nesterov)"])
                lambda_ratio = st.slider("æ­£åˆ™åŒ–å¼ºåº¦ (Lambda)", 0.01, 0.20, 0.05, 0.01)
                mu_val = st.number_input("å¹³æ»‘å‚æ•° (Mu)", value=0.01, format="%.4f", step=0.005)
                alpha = st.slider("æ­¥é•¿ (Alpha)", 0.1, 2.0, 1.0, 0.1)
                max_iter = st.number_input("æœ€å¤§è¿­ä»£æ¬¡æ•°", 20, 500, 100, 20)
            
            run_btn = st.button("å¼€å§‹é‡å»º", type="primary")

        # --- æ•°æ®å‡†å¤‡ (ä¿®æ­£ç‰ˆ) ---
        # 1. è·å–åŸå§‹æ•°æ®
        raw_orig, _, _, _ = get_isar_data()
        
        # 2. å½’ä¸€åŒ– (å…³é”®æ­¥éª¤ï¼šHuber å‚æ•° mu å¯¹æ•°æ®å°ºåº¦æ•æ„Ÿ)
        raw = raw_orig / np.max(np.abs(raw_orig))
        
        # 3. åŸºäºå½’ä¸€åŒ–æ•°æ®è®¡ç®— Ground Truth
        rd_img = compute_rd_image(raw)
        
        N_pulses = raw.shape[1]
        
        # éšæœºé‡‡æ ·æ©æ¨¡
        np.random.seed(42) 
        keep_indices = np.random.choice(N_pulses, int(N_pulses * sampling_rate), replace=False)
        mask = np.zeros(N_pulses)
        mask[keep_indices] = 1
        raw_sparse = raw * mask[None, :] 
        
        # ä¼ ç»Ÿ RD ç»“æœï¼ˆåŸºå‡†ï¼‰
        img_fft = compute_rd_image(raw_sparse)
        # ç¿»è½¬ä»¥ç¬¦åˆè§†è§‰ä¹ æƒ¯
        img_fft = np.flipud(img_fft) 
        rd_img_disp = np.flipud(rd_img)

        with col_main:
            if run_btn:
                progress_bar = st.progress(0)
                status = st.empty()
                
                # åˆå§‹åŒ–æ±‚è§£å™¨
                solver = HuberISARSolver(raw_sparse, mask, max_iter=max_iter)
                
                t_start = time.time()
                
                # --- è¿è¡Œç®—æ³• ---
                if algo_type == "Huber Gradient Descent":
                    recon = solver.huber_gradient_descent(lambda_ratio, alpha, mu_val)
                else:
                    recon = solver.huber_nesterov(lambda_ratio, alpha, mu_val)
                
                t_end = time.time()
                duration = t_end - t_start
                recon = np.flipud(recon)
                
                progress_bar.progress(100)
                status.success(f"âœ… è®¡ç®—å®Œæˆï¼è€—æ—¶: {duration:.3f} ç§’")
                
                # ç»˜å›¾å¯¹æ¯”
                fig_res = plot_isar_comparison(rd_img_disp, img_fft, recon, algo_type, duration, sampling_rate)
                st.pyplot(fig_res)
                
                # ä¿å­˜çŠ¶æ€ä¾›åˆ†æ
                st.session_state['huber_run'] = {
                    'loss_history': solver.loss_history,
                    'params': {'lambda': lambda_ratio, 'mu': mu_val, 'algo': algo_type}
                }
                
                # ç»“æœè§£è¯»
                st.info(f"""
                **åˆ†æ**ï¼š
                Huber æ–¹æ³•é€šè¿‡å¹³æ»‘åŒ– L1 èŒƒæ•°ï¼Œä½¿å¾—ç›®æ ‡å‡½æ•°å˜å¾—å¯å¾®ã€‚
                *   å¦‚æœç»“æœä¸å¤Ÿç¨€ç–ï¼ˆèƒŒæ™¯å™ªå£°å¤§ï¼‰ï¼Œå°è¯•**å‡å° Mu** æˆ– **å¢å¤§ Lambda**ã€‚
                *   å¦‚æœæ”¶æ•›å¤ªæ…¢ï¼Œå°è¯•ä½¿ç”¨ **Nesterov åŠ é€Ÿ**ã€‚
                """)

            else:
                st.info("ğŸ‘ˆ è¯·è°ƒæ•´å·¦ä¾§å‚æ•°å¹¶è¿è¡Œä»¿çœŸã€‚")
                # æ˜¾ç¤ºå ä½å›¾
                fig_holder = plot_isar_comparison(rd_img_disp, img_fft, np.zeros_like(rd_img), "Waiting...", 0, sampling_rate)
                st.pyplot(fig_holder)

    # ==========================================
    # Tab 3: æ”¶æ•›åˆ†æ
    # ==========================================
    with tab_analysis:
        st.markdown("### ğŸ“ˆ ç®—æ³•æ”¶æ•›æ€§è¯Šæ–­")
        
        if 'huber_run' in st.session_state:
            run_data = st.session_state['huber_run']
            loss_hist = run_data['loss_history']
            
            if len(loss_hist) > 0:
                col_an1, col_an2 = st.columns([2, 1])
                
                with col_an1:
                    fig_loss, ax_loss = plt.subplots(figsize=(8, 5))
                    ax_loss.plot(loss_hist, 'b-o', markersize=3, linewidth=1.5, label='Huber Loss')
                    ax_loss.set_title("Objective Function Descent")
                    ax_loss.set_xlabel("Iteration (k)")
                    ax_loss.set_ylabel("Loss Value")
                    ax_loss.grid(True, linestyle='--', alpha=0.5)
                    ax_loss.legend()
                    st.pyplot(fig_loss)
                    
                with col_an2:
                    st.markdown("#### è¯Šæ–­æŠ¥å‘Š")
                    init_loss = loss_hist[0]
                    final_loss = loss_hist[-1]
                    
                    st.metric("åˆå§‹ Loss", f"{init_loss:.2e}")
                    st.metric("æœ€ç»ˆ Loss", f"{final_loss:.2e}")
                    
                    st.markdown(f"""
                    **å½“å‰è®¾ç½®**ï¼š
                    * ç®—æ³•: `{run_data['params']['algo']}`
                    * Mu: `{run_data['params']['mu']}`
                    
                    **è§‚å¯Ÿ**ï¼š
                    Huber æ–¹æ³•é€šå¸¸æ¯” ISTA æ”¶æ•›æ›´å¹³æ»‘ï¼Œå› ä¸ºå®ƒé¿å…äº†ç¡¬æ€§çš„é˜ˆå€¼æˆªæ–­æ“ä½œã€‚
                    """)
            else:
                st.warning("æ—  Loss æ•°æ®ã€‚")
        else:
            st.info("è¯·å…ˆåœ¨ [ä»¿çœŸå®éªŒ] æ ‡ç­¾é¡µè¿è¡Œä¸€æ¬¡ç®—æ³•ã€‚")

if __name__ == "__main__":
    render()